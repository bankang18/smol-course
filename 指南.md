![smolcourse 图片](./banner.png)

# 一个 smol 课程

这是一门关于针对特定用例调整语言模型的实用课程。这是开始调整语言模型的一个便捷方式，因为一切都可以在大多数本地机器上运行。GPU 要求极低，且无需付费服务。本课程基于 [SmolLM2](https://github.com/huggingface/smollm/tree/main) 系列模型，但你可以将在这里学到的技能转移到更大的模型或其他小型语言模型上。

<a href="http://hf.co/join/discord">
<img src="https://img.shields.io/badge/Discord-7289DA?&logo=discord&logoColor=white"/>
</a>

<div style="background: linear-gradient(to right, #e0f7fa, #e1bee7, orange); padding: 20px; border-radius: 5px; margin-bottom: 20px; color: purple;">
    <h2>参与是开放的、免费的，现在就开始！</h2>
    <p>本课程公开且同行评审。要参与课程，请<strong>开启一个 pull 请求</strong>，并提交你的作品供评审。以下是步骤：</p>
    <ol>
        <li>在这里 Fork 仓库 <a href="https://github.com/huggingface/smol-course/fork"></a></li>
        <li>阅读材料，进行更改，做练习，添加自己的示例。</li>
        <li>在 december_2024 分支上开启 PR</li>
        <li>接受评审并合并</li>
    </ol>
    <p>这将帮助你学习并建立一个始终在改进的社区驱动课程。</p>
</div>

我们可以在[这个讨论主题](https://github.com/huggingface/smol-course/discussions/2#discussion-7602932)中讨论这个过程。

## 课程大纲

本课程以实用、动手的方式教授如何处理小型语言模型，从初始训练到生产部署。

| 模块 | 描述 | 状态 | 发布日期 |
|--------|-------------|---------|--------------|
| [指令调整](./1_instruction_tuning) | 学习有监督的微调、聊天模板以及基本的指令遵循 | ✅ 准备就绪 | 2024年12月3日 |
| [偏好对齐](./2_preference_alignment) | 探索DPO和ORPO技术来与人类偏好对齐模型 | ✅ 准备就绪  | 2024年12月6日 |
| [参数高效微调](./3_parameter_efficient_finetuning) | 学习LoRA、提示调优和高效适应方法 | ✅ 准备就绪 | 2024年12月9日 |
| [评估](./4_evaluation) | 使用自动基准并创建自定义领域评估 | ✅ 准备就绪 | 2024年12月13日 |
| [视觉语言模型](./5_vision_language_models) | 为视觉语言任务调整多模态模型 | ✅ 准备就绪 | 2024年12月16日 |
| [合成数据集](./6_synthetic_datasets) | 创建并验证用于训练的合成数据集 | ✅ 准备就绪 | 2024年12月20日 |
| [推理](./7_inference) | 高效地使用模型进行推理 | ✅ 准备就绪 | 2025年1月8日 |
| [智能体](./8_agents) | 建立你自己的智能代理 AI | ✅ 准备就绪 | 2025年1月13日 ||

## 为什么要小型语言模型？

尽管大型语言模型表现出令人印象深刻的能```bash
uv 创建虚拟环境 --python 3.11.0
uv 同步
```

### 使用 `pip`

所有示例均在相同的 **Python 3.11** 环境中运行，因此您应该创建一个环境并如下安装依赖项：

```bash
# python -m venv .venv
# source .venv/bin/activate
pip install -r requirements.txt
```

### Google Colab

**在 Google Colab 中**，您需要根据所使用的硬件灵活安装依赖项。如下所示：

```bash
pip install transformers trl datasets huggingface_hub
```